# F5

## Routing

- The BIG-IP system maintains two kinds of routes:
    - Management routes: Management routes are routes that the BIG-IP system uses to forward traffic through the special management interface. The BIG-IP system stores management routes in the Linux (that is, kernel) routing table.
    - TMM routes: TMM routes are routes that the BIG-IP system uses to forward traffic through the Traffic Management Microkernel (TMM) interfaces instead of through the management interface. The BIG-IP system stores TMM routes in both the TMM and kernel routing tables.
- VIPs can be advertised to dynamic routing, based on the fact if they are available or not
- It is configured in Virtual address list section
 

## Traffic groups

- Several traffic groups may exist, Host A may be active for traffic group 1 and Host B for traffic group B
- We can control to which traffic group which floating IP or VIP is connected: Interfaces section and Virtual Addresses Section

## Monitors

- In-TMM monitoring - capability to run ICMP, TCP, HTTP, and HTTPS monitors in the TMM process, which allows monitors to consume fewer system resources and scale more efficiently. Additionally, the feature uses SSL acceleration hardware and Server SSL profiles for HTTPS monitors

## Persistence

- LB methods define how to distribute initial packets of session, for example based on least connections.
- Persistence profile then keeps this distributed session on one pool member, for example based on destination address.
- Connection requests from the client that do not use persistence are load balanced according to the currently selected load balancing method.
- Persistent profile is attached to virtual server as a profile
- Balancing method is attached to pool
- Most methods can work on node level and member level
- Ensure that client requests are directed to the same pool member throughout the life of a session or during subsequent sessions
- When you enable persistence, returning clients can bypass load balancing and instead connect to the server to which they last connected in order to access their saved information.
- The BIG-IP system keeps session data for a period of time that you specify
- You can write an iRule, which enables a persistence type for particular requests (for example, for HTTP traffic that includes a certain cookie version only)
- Default persistence timeout is 180 or 300 s

Persistent profiles:

- Cookie persistence - from web server
- Destination address affinity persistence - based solely on the destination IP address of a packet
- Hash persistence - a hash value may be created based on Source IP, Destination IP, Destination Port
- Microsoft® Remote Desktop Protocol persistence
- SIP persistence
- Source address affinity persistence
- SSL persistence - SSL session ID
- Universal persistence - any piece of data

Show persistence data

```
show ltm persistence persist-records
```

Cookie persistence methods

- Cookie Hash
- HTTP Cookie Insert - default method - By default, the cookie is named BIGipServer<pool_name> is inserted into HTTP reply from server
- HTTP Cookie Passive - not recomended - the server provides the cookie, formatted with the correct server information and timeout
- HTTP Cookie Rewrite - recomended - cookie is intercepted and rewritten - BIG-IP system intercepts a Set-Cookie header, named BIGipCookie -  The new cookie is named BIGipServer<pool_name> and it includes the address and port of the server handling the connection

Persistence mirroring

- Need to be enabled in a profile

The BIG-IP system can mirror persistence information between peers for the following persistence profiles:

- Destination address affinity
- Hash
- Host
- Microsoft Remote Desktop
- SIP
- Source address affinity
- SSL
- Universal

Show mirriored persistence records

```
tmsh show /ltm persistence persist-records
```

## Bandwidth controllers

- You apply a bandwidth control policy to a virtual server, packet filter, or route domain, you can apply only one policy at a time, and that is a static policy
- Using iRules®, you can combine static and dynamic bandwidth control policies up to eight policies on a connection, but only one of the eight policies can be a dynamic policy. A packet is transmitted only when all the attached policies allow it. The system as a whole supports a maximum of 1024 policies
- Applying a bandwidth controller policy to a route domain affects all traffic transmitted by the BIG-IP system to VLANs in the route domain, including health monitors and DNS queries
- Only static bandwidth control policies support SNMP queries
- Bandwidth controller is the updated version of rate shaping on the BIG-IP® system. These features are mutually exclusive. You can configure and use either rate shaping or bandwidth controllers, but not both. Bandwidth controllers include distributed control, subscriber fairness, and support for a maximum rate of 320 Gbps. Rate shaping is hierarchical and supports minimum bandwidth (committed information rate), priority, and flow fairness
-  Acceleration > Bandwidth Controllers 
-  Configure max rate 1 Mbps to 320 Gbps
- Add controller to virtual server

## Local policy

- Draft policy, publish the policy, and then associate the published policy with a virtual server
- Match strategy, conditions, actions
- Matching strategies: a first-match, best-match, and all-match, user-defined
- In a best-match or first-match strategy, a rule without conditions becomes the default rule, when the rule is the last entry in the Rules list
- In an all-match strategy, when multiple rules match, but specify conflicting actions, only the action of the best-match rule is implemented. A best-match rule can be the lowest ordinal, the highest priority, or the first rule that matches in the Rules list: The lower rule the better during conflict!
- When you add a new rule, it is added to the end
- Many condition types: HTTP headers, SSL headers, TCP headers, Geo IP, CPU usage, URL category
- Different selectors: host, port, full strings, value, path...
- Different conditions: is, is not, in data group, any of
- Many actions:
    - Blocking traffic
    - Rewriting a URL
    - Logging traffic
    - Adding a specific header
    - Redirecting traffic to a different pool member
    - Selecting a specific Web Application policy

### Disable Resp mode in SSLO for all traffic

- Create LTM policy Local traffic > Policies
- Create rule
- Condition: All traffic, Action: Disable response adapt at response time
- Apply policy to ICAP service in SSLO

### Disable all methods except PUT and POST

- Condition: HTTP Method is not any of PUT POST at request time
- Action: Disable request adapt at request time

### Disable Request Adapt, Response Adapt only for certain files

- Strategy: execute all rules
- 3 rules
- Rule 1: Disable request Adapt - HTTP Method exists at request time - Disable request adapt at request time
- Rule 2 - HTTP Status full string exists at response time - Disable Response Adapt at Response time
- Rule 3: HTTP Header full string named Content-Type is in datagroup "datagroup name" at response time - Enable response adapt at response time

Datagroup type string contents:

- application/octet-stream
- application/zip
- application/x-7z-compressed

## iRules

Disable ICAP Respmode for reponses smaller then 1000 bytes. iRule is attached to ssloS_Icap-t-4 in SSLO

```
when HTTP_RESPONSE {

if { ( [HTTP::header exists Content-Length] ) and ( [expr { [HTTP::header Content-Length] <= 1000}] ) } {
            ADAPT::enable response false
      }
  }
```

## SSLO integration with Sandbox via ICAP

- This integration can and work fine
- Response ICAP mode is configured to send all HTTP replies to Sandbox
- ICAP virtual server TCP profile should be configured to increase idle timeout from 300 sec to 600 for heavy files
- File size limit can be configured via iRule, which is attached to ICAP virtual server
- What we send to Sandbox is configured using Content-Type field in HTTP and MIME types and local policy attached to ICAP Service in SSLO
- Be aware of a lot of garbage generated by Chrome and Windows updates - we can filter it in SSLO Security policy based on dst IPs and URLs via custom URL category
- Files which are downloaded via Javascript - can provide issues
- How to find out which request SSLO sends to Sandbox, more specifically Host, we need to launch on SSLO
- Sandbox in reply sends either block page and ICAP block code, or ICAP allow code plus HTTP reply(file) itself
- F5 sends to Sandbox the following:
    - RESPMOD icap://10.2.55.113:1344/response ICAP/1.0\r\n
    - X-Client-IP: 192.168.1.20\r\n
    - HTTP request
    - HTTP response - file, html page, json...
    - In HTTP reply F5 looks at: http.content_type: application/octet-stream

```
tcpdump -i 0.0 -A host 10.2.55.113 | grep Host

Host: 10.2.55.113:1344
Host: data-edge.smartscreen.microsoft.com
Host: 10.2.55.113:1344
Host: dl.google.com
```
10.2.55.113 - Sandbox IP  
This way we can know which domains to block to fight updates requests

## SNI routing

Using SNI we can route traffic to a destination without having to terminate the SSL connection. This enables several benefits including:
- Reduced number of Public IPs
- Simplified configuration
- More intelligent routing of TLS traffic
- No SSL profile use

Using SNI Routing we can handle everything on a single virtual server / Public IP address. There are 3 methods for performing SNI Routing with BIG-IP
- iRule with binary scan 
    - a. Article by Colin Walker code attribute to Joel Moses 
    - b. Code Share by Stanislas Piron
- iRule with SSL::extensions
- Local Traffic Policy

Local policy:
- SSl extension - server name - is-  any of - app1.example.com - at ssl client hello
- Forward traffic - to - pool - pool_name - at SSL client hello time

## One connect

## Cli

Add management route

```
create /sys management-route default gateway 192.168.5.1
save sys config
```